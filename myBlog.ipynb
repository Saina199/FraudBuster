{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile App Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is my short-term partnership with a sneaker mobile app marketplace through the Insight Data Science Program where I developed and implemented a fraud detection model to verify the orders on this mobile app. Security and, of course, identification of legitimate user behavior are crucial to any mobile-app marketplace.  This company has been founded on the premise of protecting sneaker lovers from ordering counterfeits while paying the price of genuine products.  \n",
    "\n",
    "This mobile app marketplace has been dealing with fraud like any other online marketpplace. One form of fraud on this mobile-app is when the seller attempts to sell the fake sneaker as a genuine pair.  The other form of fraud is very simillar to many fraudulent orders when fraudster pays using stolen credit card information.  In such cases, the buyer might intend to resell the sneakers for higher price.  Either way, the occurrences of such activities are harmful to the reputation of the marketplace: the valuable customers might feel unsafe using this platform for their transaction.\n",
    "\n",
    "In the following, the steps towards the creation of fraud detector model is described in details.  Please refer to <strong>FraudBuster.ipynb</strong> in this git resiprosity for the python implementation of this project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [DataBase](#Data)\n",
    " \n",
    " [Existing Fraud Detector](#existing)\n",
    "  \n",
    " [Feature Selection and Engineering](#Feature)\n",
    "\n",
    " [FraudBuster](#FraudBuster)\n",
    " \n",
    " [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data'></a>\n",
    "## DataBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company's database which has been logged for about 18 months (upto the start of this project), includes slightly less than 110K completed orders to be studied for this work.  This number of orders has been placed by about 30K unique users.  The given database includes 36 tables with about 15 columns (on average) each.  Although getting through all this data could become tedious, it is very important to understand the meaning of every collected data that might be potential of revealing some characteristics of the order.  \n",
    "\n",
    "Therefore, I went through every field one by one and tried to understand if this information could signify any specific behavior of the fraudulent orders.  Note that sometimes not the field itself but its relation to another field could represent a new property that help with the fraud identification.  This was in fact the case for half of the features that I ended up sending through my fraud detector pipeline and will be discussed later.\n",
    " \n",
    "Another important note is that to not consider the fields that could only be known after the order is being placed.  For example, some fields record the timestamp of buyer or seller's confirmation or cancellation.  This information should not be considered in the fraud detector model as it will not be available at the time of order placement.  Keeping that in mind, let us review some fact on the existing fraud detection system at this mobile app marketplace.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='existing'></a>\n",
    "## Existing Fraud Detector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the company identifies the fraudualent orders through a multistage process.  30% of the orders that are placed using credit card are being verified by third-party.  The other 70% of orders are placed using PayPal and being verified by PayPal protection.  Finally, after integrating all this infromation from different sources, the company investigates the suspicious orders manually to finalize the verification.  The third party achieves 74% recall with a low precision of 30%.  The low precision indicate a large false positive rate which creates unnecessary work for the company. This model system is not the most efficient system and a unified, automated system that can verify any order at any time in an efficient way is highly desired.  The final performance of the current fraud detector sums up to 52% recall and 8.7% false positive rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='Feature'></a> \n",
    "## Feature Selection and Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pipeline of my fraud detection, data exploration and feature selection and engineering get the highest credit in terms of performance.  Let us remember that the data collected after the fact should not be considered in the order verification as in reality it will not be available at the time of order placement.  For example, there are specific data on the timestamp of acceptance of an order, confirming the shipment and status of the sneakers which could only be collected long (hours or days) after the order is been taken place and should not be considered as a feature to verify an order. \n",
    "\n",
    "Keeping that in mind, the first important step is to decide where to start.  So let's go back to the first step.  We are at the middle of an event happening which is an order taking place.  The question is, if this order is legitimate.  To address this question, we have to see what information do we have at this exact moment.  Here is why I decided to divide the information on every transaction to three pools: order information, user information and the sneaker information.  The order informatiom comes at the time of an even; infomration such as billing and shipping addresses, the IP address, and the device being used to place the order.  The other source of information is the user.  Every order is an event that is not possible unless a user has created an account to make that event. This brings alother source of information which I could take advantage of.  Every user could get associated with the number of signing in to the mobile-app.  They might leave out some information on their social network (ie. instagram and twitter). In addition, the user could also be identified by their device, their previous IP address, and if they are interested in buying or selling higher number of sneakers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='FraudBuster'></a>\n",
    "## FraudBuster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started with more than 30 features and I ended up settling with 14 (through implementing backward stepwaise selection): 7 of which I created from the available data, and the rest I selected from the existing ones.  My created features are a combination of indicators (categorical) and continuous variables.  I defined an indicator to verify whether the current IP of an event has indeed been used by this specific user.  Another categorical variable verifies if the zip-code of the billing and shipping addresses of the order are the same.  The third and fourth indicator variables indicate whether a user authenticated his identity by using a social network (Instagram or Twitter) account.  In addition to these 4 categorical attributes, I created three interesting continuous variables that turn out to play important roles in verifying the legitimacy of the orders: how frequently a device is being used on the mobile-app is a good indication of whether the order is fraudulent.  A person with bad intentions is more likely to use random devices and use them only once. Another attribute that I have identified in my modeling pipeline was the popularity of the sneaker model.  Some sneaker models are more popular and therefore more prone to counterfeiting in the market.  The last and most important feature is the duration from the time a user has created his/her account to the time of the first activity.  In fact, it turned out that this time feature is most important in distinguishing fraudulent orders from legitimate ones.  Fraudsters act faster: they act 100 minutes faster than the non-fraudsters!  \n",
    "\n",
    "It was interesting to see that after considering these 14 features and training the data using a random forest classifier, three of the first four important features are those features that I have created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id='Conclusion'></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, I applied a Random Forest Classifier (RF) to my training data and created a model to identify the fraudulent orders from the non-fraudulent ones.  I chose RF over logistic regression as it can handle mix features.  My classification model outperforms the current model with an impressive improvement.  Recall is 87% and the precision is 85%. the Specifically, the recall is 1.67 times higher, and the false positive rate is 14 times smaller than the current model.  I have tuned my proability threshold for a performance of high recall and precision.  With a different tune, I could have boosted my recall to more than 90% but that would be with the cost of dropping precision to about 65%.  Since, missing every fraud sneaker order costs the company $300, I would advice on higher recall than precision, but until we have not defined an appropriate cost function based on different variables, I evauate things at a conservative level.\n",
    "\n",
    "In summary, implementing this model will save the mobile-app more than $250K annually and a lot of expensive man hours.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
